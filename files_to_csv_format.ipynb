{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtSt1i812/kmD979grtGyF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekmanral011/hackathon_spg_slb/blob/main/files_to_csv_format.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting .dev files to csv files**"
      ],
      "metadata": {
        "id": "dC0DnFBr_vHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-ready: robust parser for .dev files with irregular spacing\n",
        "import re\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from io import StringIO\n",
        "\n",
        "# Upload the .dev file\n",
        "print(\"Upload your .dev/.txt file\")\n",
        "uploaded = files.upload()\n",
        "dev_file = list(uploaded.keys())[0]\n",
        "print(\"Parsing:\", dev_file)\n",
        "\n",
        "def try_float(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Read full content\n",
        "with open(dev_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    lines = [ln.rstrip(\"\\n\\r\") for ln in f]\n",
        "\n",
        "# Drop blank lines and common comment lines (start with # or ~ or //)\n",
        "lines = [ln for ln in lines if ln.strip() and not ln.strip().startswith((\"#\", \"~\", \"//\"))]\n",
        "\n",
        "# If file is quoted CSV-like, try simple csv first\n",
        "sample = \"\\n\".join(lines[:30])\n",
        "if \"\\t\" in sample:\n",
        "    primary_sep = \"\\t\"\n",
        "elif sample.count(\",\") >= sample.count(\" \"):\n",
        "    primary_sep = \",\"\n",
        "else:\n",
        "    primary_sep = None  # fallback to regex whitespace split\n",
        "\n",
        "rows = []\n",
        "if primary_sep in (\",\", \"\\t\"):\n",
        "    # Try parsing by chosen separator but fallback to regex if row lengths vary\n",
        "    for ln in lines:\n",
        "        parts = [p.strip() for p in ln.split(primary_sep)]\n",
        "        rows.append(parts)\n",
        "    # check consistency\n",
        "    lens = set(len(r) for r in rows)\n",
        "    if len(lens) > 1:\n",
        "        # inconsistent -> fallback to regex whitespace\n",
        "        primary_sep = None\n",
        "\n",
        "if primary_sep is None:\n",
        "    # Split on any run of whitespace (handles variable spaces/tabs)\n",
        "    for ln in lines:\n",
        "        # If line contains commas inside quotes, remove surrounding quotes then split commas first\n",
        "        if '\"' in ln or \"'\" in ln:\n",
        "            # remove surrounding quotes around delimited values to avoid splitting inside quotes\n",
        "            # simple approach: replace commas inside quotes with a special token\n",
        "            def _replace_inside_quotes(s, char=\",\", token=\"<<COMMA>>\"):\n",
        "                out = []\n",
        "                in_q = False\n",
        "                qchar = None\n",
        "                for ch in s:\n",
        "                    if ch in ('\"', \"'\"):\n",
        "                        if not in_q:\n",
        "                            in_q = True\n",
        "                            qchar = ch\n",
        "                        elif ch == qchar:\n",
        "                            in_q = False\n",
        "                            qchar = None\n",
        "                        out.append(ch)\n",
        "                    elif in_q and ch == char:\n",
        "                        out.append(token)\n",
        "                    else:\n",
        "                        out.append(ch)\n",
        "                return \"\".join(out)\n",
        "            ln2 = _replace_inside_quotes(ln, \",\", \"<<COMMA>>\")\n",
        "            parts = re.split(r'\\s+', ln2.strip())\n",
        "            # restore commas inside tokens\n",
        "            parts = [p.replace(\"<<COMMA>>\", \",\") for p in parts]\n",
        "        else:\n",
        "            parts = re.split(r'\\s+', ln.strip())\n",
        "        rows.append(parts)\n",
        "\n",
        "# Normalize row lengths by padding with empty strings / NaN\n",
        "max_cols = max(len(r) for r in rows)\n",
        "norm_rows = [r + [\"\"]*(max_cols - len(r)) for r in rows]\n",
        "\n",
        "# Detect header: if first row contains any non-numeric token (and >0 alphabetic tokens), treat it as header\n",
        "first_row = norm_rows[0]\n",
        "alpha_tokens = sum(1 for t in first_row if re.search(r'[A-Za-z]', t))\n",
        "numeric_tokens = sum(1 for t in first_row if try_float(t))\n",
        "has_header = alpha_tokens > numeric_tokens and alpha_tokens > 0\n",
        "\n",
        "if has_header:\n",
        "    header = [h.strip() if h.strip() else f\"col{i+1}\" for i,h in enumerate(first_row)]\n",
        "    data_rows = norm_rows[1:]\n",
        "else:\n",
        "    # create generic headers col_1 ... col_n\n",
        "    header = [f\"col_{i+1}\" for i in range(max_cols)]\n",
        "    data_rows = norm_rows\n",
        "\n",
        "# Build DataFrame\n",
        "df = pd.DataFrame(data_rows, columns=header)\n",
        "\n",
        "# Try convert numeric columns to numeric dtype\n",
        "for col in df.columns:\n",
        "    # replace common missing markers\n",
        "    df[col] = df[col].replace([\"\", \"-\", \"NA\", \"N/A\", \"null\", \"None\"], pd.NA)\n",
        "    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
        "\n",
        "# Save CSV\n",
        "out_csv = dev_file.rsplit(\".\",1)[0] + \"_converted.csv\"\n",
        "df.to_csv(out_csv, index=False)\n",
        "print(f\"Saved: {out_csv}\")\n",
        "print(\"\\nDetected columns:\", len(df.columns))\n",
        "print(df.head(10))\n",
        "\n",
        "# Offer download\n",
        "files.download(out_csv)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "PC5GGCAju1rZ",
        "outputId": "0678689c-6722-4fcf-c8c1-ec126ae33b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your .dev/.txt file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c2ccffd4-dc20-4f0c-a41d-745ca3c18fa5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c2ccffd4-dc20-4f0c-a41d-745ca3c18fa5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving A1.dev to A1.dev\n",
            "Parsing: A1.dev\n",
            "Saved: A1_converted.csv\n",
            "\n",
            "Detected columns: 10\n",
            "            MD            X            Y            Z          TVD  \\\n",
            "0  1713.982300  454755.6538  6783765.045 -1713.982300  1713.982300   \n",
            "1  1963.229574  454563.1755  6783765.045 -1872.337324  1872.337324   \n",
            "2  1977.535394  454552.0157  6783765.045 -1881.287427  1881.287427   \n",
            "3  1991.841213  454540.6359  6783765.045 -1889.956128  1889.956128   \n",
            "4  2006.147033  454529.0432  6783765.045 -1898.338021  1898.338021   \n",
            "5  2020.452853  454517.2449  6783765.045 -1906.427882  1906.427882   \n",
            "6  2034.758673  454505.2483  6783765.045 -1914.220668  1914.220668   \n",
            "7  2049.064492  454493.0609  6783765.045 -1921.711520  1921.711520   \n",
            "8  2063.370312  454480.6903  6783765.045 -1928.895770  1928.895770   \n",
            "9  2077.676132  454468.1441  6783765.045 -1935.768938  1935.768938   \n",
            "\n",
            "           DX   DY   AZIM       INCL  DLS  \n",
            "0    0.000000  0.0  270.0  50.555312  0.0  \n",
            "1 -192.478284  0.0  270.0  50.555312  0.0  \n",
            "2 -203.638100  0.0  270.0  51.985894  3.0  \n",
            "3 -215.017884  0.0  270.0  53.416476  3.0  \n",
            "4 -226.610542  0.0  270.0  54.847057  3.0  \n",
            "5 -238.408847  0.0  270.0  56.277639  3.0  \n",
            "6 -250.405443  0.0  270.0  57.708221  3.0  \n",
            "7 -262.592854  0.0  270.0  59.138803  3.0  \n",
            "8 -274.963481  0.0  270.0  60.569385  3.0  \n",
            "9 -287.509612  0.0  270.0  61.999967  3.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-2123604016.py:106: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9abbfc89-6fbe-45b8-b23a-eb5fbb76689f\", \"A1_converted.csv\", 6985)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YeCXZrZd_4dF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ChyumqP_Urg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**converting las file to csv file**"
      ],
      "metadata": {
        "id": "5pVe6VaI_5Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependency\n",
        "!pip install lasio\n",
        "\n",
        "import os\n",
        "import lasio\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "\n",
        "# Prompt user to upload multiple LAS files\n",
        "print(\"Upload one or more .las files (select multiple using Ctrl/Cmd + click)...\")\n",
        "uploaded = files.upload()   # upload multiple files at once\n",
        "\n",
        "if not uploaded:\n",
        "    raise SystemExit(\"No files uploaded.\")\n",
        "\n",
        "out_csv_paths = []\n",
        "\n",
        "def safe_read_las_to_df(path):\n",
        "    \"\"\"Try lasio.read, fallback to simple manual parse if needed.\"\"\"\n",
        "    try:\n",
        "        las = lasio.read(path)\n",
        "        df = las.df()\n",
        "        # lasio sometimes returns empty DF; handle that\n",
        "        if df is None or df.shape[0] == 0:\n",
        "            raise ValueError(\"lasio returned empty dataframe\")\n",
        "        # Reset index so depth becomes a column\n",
        "        df = df.reset_index()\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"lasio failed for {path}: {e}. Trying simple fallback parser...\")\n",
        "        # Simple fallback: collect lines after ~A and split whitespace\n",
        "        data = []\n",
        "        started = False\n",
        "        with open(path, \"r\", errors=\"ignore\") as f:\n",
        "            for line in f:\n",
        "                ln = line.rstrip(\"\\n\\r\")\n",
        "                if ln.strip().upper().startswith(\"~A\"):  # data section\n",
        "                    started = True\n",
        "                    continue\n",
        "                if not started:\n",
        "                    continue\n",
        "                if not ln.strip():\n",
        "                    continue\n",
        "                parts = ln.strip().split()\n",
        "                data.append(parts)\n",
        "        if not data:\n",
        "            raise ValueError(\"Fallback parser found no data\")\n",
        "        # pad rows to equal length\n",
        "        max_cols = max(len(r) for r in data)\n",
        "        norm = [r + [\"\"]*(max_cols - len(r)) for r in data]\n",
        "        col_names = [f\"col_{i+1}\" for i in range(max_cols)]\n",
        "        df = pd.DataFrame(norm, columns=col_names)\n",
        "        # try convert numeric columns where possible\n",
        "        for c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
        "        return df\n",
        "\n",
        "# Process each uploaded file\n",
        "for fname in uploaded.keys():\n",
        "    # Save uploaded bytes to disk (files.upload already did this in Colab)\n",
        "    print(f\"Processing: {fname}\")\n",
        "    root, ext = os.path.splitext(fname)\n",
        "    ext_l = ext.lower()\n",
        "    try:\n",
        "        if ext_l == \".las\" or ext_l == \".log\":\n",
        "            df = safe_read_las_to_df(fname)\n",
        "        else:\n",
        "            # If user uploaded a CSV-like .las with different ext, still try lasio\n",
        "            try:\n",
        "                df = safe_read_las_to_df(fname)\n",
        "            except Exception:\n",
        "                # As a fallback, try pandas with whitespace delimiter\n",
        "                df = pd.read_csv(fname, sep=r\"\\s+\", engine=\"python\", header=None)\n",
        "        out_name = f\"{root}_converted.csv\"\n",
        "        df.to_csv(out_name, index=False)\n",
        "        out_csv_paths.append(out_name)\n",
        "        print(f\" -> saved: {out_name} (rows: {len(df)}, cols: {df.shape[1]})\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR converting {fname}: {e}\")\n",
        "\n",
        "if not out_csv_paths:\n",
        "    raise SystemExit(\"No CSVs were generated.\")\n",
        "\n",
        "# Offer individual downloads\n",
        "print(\"\\nPreparing downloads...\")\n",
        "for p in out_csv_paths:\n",
        "    print(\"Downloading:\", p)\n",
        "    files.download(p)\n",
        "\n",
        "# Also create a ZIP with all CSVs for convenience\n",
        "zip_name = \"las_csvs_bundle.zip\"\n",
        "with zipfile.ZipFile(zip_name, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    for p in out_csv_paths:\n",
        "        zf.write(p, arcname=os.path.basename(p))\n",
        "\n",
        "print(f\"\\nCreated ZIP: {zip_name}\")\n",
        "files.download(zip_name)\n",
        "\n",
        "print(\"Done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "Wt8LvXz2DZan",
        "outputId": "2b0088fc-e7dc-4c6d-805b-011b020df36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lasio in /usr/local/lib/python3.12/dist-packages (0.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lasio) (2.0.2)\n",
            "Upload one or more .las files (select multiple using Ctrl/Cmd + click)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22876e5e-bc59-4e64-b83e-3a591637b8b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22876e5e-bc59-4e64-b83e-3a591637b8b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving A1.las to A1.las\n",
            "Processing: A1.las\n",
            " -> saved: A1_converted.csv (rows: 2521, cols: 6)\n",
            "\n",
            "Preparing downloads...\n",
            "Downloading: A1_converted.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fca61290-1799-49d7-9cd0-17811a513af7\", \"A1_converted.csv\", 119294)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Created ZIP: las_csvs_bundle.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e33fb1f-a9b0-4f93-86ea-00e854e5caba\", \"las_csvs_bundle.zip\", 43960)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYKSnc2h_XcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting fault stick depth files to Csv files **"
      ],
      "metadata": {
        "id": "GW2zv8n3ABcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Select your ASCII file\n",
        "filename = list(uploaded.keys())[0]\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def make_unique(colnames):\n",
        "    counts = {}\n",
        "    new_cols = []\n",
        "    for col in colnames:\n",
        "        if col in counts:\n",
        "            counts[col] += 1\n",
        "            new_cols.append(f\"{col}_{counts[col]}\")\n",
        "        else:\n",
        "            counts[col] = 0\n",
        "            new_cols.append(col)\n",
        "    return new_cols\n",
        "\n",
        "# Read the file and find where the header ends\n",
        "with open(filename, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    header_end = 0\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(r'END HEADER', line, re.IGNORECASE):\n",
        "            header_end = i + 1\n",
        "            break\n",
        "        if line.strip().startswith('#') or line.strip() == '':\n",
        "            continue\n",
        "        if header_end == 0 and re.search(r'[A-Za-z]', line):\n",
        "            header_end = i\n",
        "            break\n",
        "\n",
        "# Try to extract column names from the first non-header line\n",
        "col_line = lines[header_end].strip()\n",
        "if ',' in col_line:\n",
        "    sep = ','\n",
        "elif '\\t' in col_line:\n",
        "    sep = '\\t'\n",
        "else:\n",
        "    sep = None  # whitespace\n",
        "\n",
        "# If the line looks like column names, use it\n",
        "if re.search(r'[A-Za-z]', col_line):\n",
        "    colnames = re.split(sep if sep else r'\\s+', col_line)\n",
        "    colnames = make_unique(colnames)\n",
        "    skiprows = header_end + 1\n",
        "else:\n",
        "    colnames = None\n",
        "    skiprows = header_end\n",
        "\n",
        "# Read the data\n",
        "if sep:\n",
        "    df = pd.read_csv(filename, sep=sep, skiprows=skiprows, names=colnames)\n",
        "else:\n",
        "    df = pd.read_csv(filename, delim_whitespace=True, skiprows=skiprows, names=colnames)\n",
        "\n",
        "# Clean up string columns\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = df[col].astype(str).str.strip('\"').str.strip()\n",
        "\n",
        "# Preview\n",
        "df.head()\n",
        "df.to_csv(filename + '.csv', index=False)\n",
        "files.download(filename + '.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "Urn9G3P8H_AD",
        "outputId": "afe83f0e-4916-442e-e156-0559916675ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a2a3cc21-c2ce-4cef-a9c7-15412626b4e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a2a3cc21-c2ce-4cef-a9c7-15412626b4e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Boundary_Fault to Boundary_Fault (1)\n",
            "Saving Boundary_Fault_West to Boundary_Fault_West (1)\n",
            "Saving Branched_Fault_NW to Branched_Fault_NW (1)\n",
            "Saving Closing_Fault_East to Closing_Fault_East (1)\n",
            "Saving Closing_Fault_South to Closing_Fault_South\n",
            "Saving Closing_Fault_South_1 to Closing_Fault_South_1\n",
            "Saving Closing_Fault_South_2 to Closing_Fault_South_2\n",
            "Saving Closing_Fault_South_3 to Closing_Fault_South_3\n",
            "Saving Closing_Fault_West_1 to Closing_Fault_West_1\n",
            "Saving Closing_Fault_West_2 to Closing_Fault_West_2\n",
            "Saving Closing_Fault_West_3 to Closing_Fault_West_3\n",
            "Saving Main_Fault_East_1 to Main_Fault_East_1\n",
            "Saving Main_Fault_East_2 to Main_Fault_East_2\n",
            "Saving Main_Fault_NE to Main_Fault_NE\n",
            "Saving Main_Fault_NS_1 to Main_Fault_NS_1\n",
            "Saving Main_Fault_NS_2 to Main_Fault_NS_2\n",
            "Saving Main_Fault_South to Main_Fault_South\n",
            "Saving Main_Fault_West_1 to Main_Fault_West_1\n",
            "Saving Main_Fault_West_2a to Main_Fault_West_2a\n",
            "Saving Main_Fault_West_3a to Main_Fault_West_3a\n",
            "Saving NNE-SSW to NNE-SSW\n",
            "Saving Truncating_Fault to Truncating_Fault\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3574265439.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df = pd.read_csv(filename, delim_whitespace=True, skiprows=skiprows, names=colnames)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90147d25-7ac2-4497-ab0d-513b68708b53\", \"Boundary_Fault (1).csv\", 2336)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_XKsvLP_caP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Fault polygons files to csv format**"
      ],
      "metadata": {
        "id": "5GUYkjUvAitA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab: parse multiple Petrel ASCII / text files -> individual CSVs + one ZIP\n",
        "!pip install -q --no-warn-script-location pandas\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import re, zipfile, os\n",
        "from io import StringIO\n",
        "\n",
        "print(\"Select one or more Petrel ASCII / text files to upload (Ctrl/Cmd+click to multi-select)...\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise SystemExit(\"No files uploaded.\")\n",
        "\n",
        "# Helper: detect sentinel values in header text like: NULL . -999.25 : NULL VALUE\n",
        "def detect_sentinels(text, max_lines=200):\n",
        "    pat = re.compile(r'NULL[^0-9\\-\\+]*([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)', re.IGNORECASE)\n",
        "    sents = set()\n",
        "    for i, line in enumerate(text.splitlines()):\n",
        "        if i > max_lines: break\n",
        "        m = pat.search(line)\n",
        "        if m:\n",
        "            try:\n",
        "                sents.add(float(m.group(1)))\n",
        "            except:\n",
        "                pass\n",
        "    return sorted(sents)\n",
        "\n",
        "# Replace sentinels (exact numeric matches) with pandas NaN\n",
        "def replace_sentinels_in_df(df, sentinels):\n",
        "    if not sentinels:\n",
        "        return df\n",
        "    repl = {s: pd.NA for s in sentinels}\n",
        "    repl.update({str(s): pd.NA for s in sentinels})\n",
        "    df = df.replace(repl)\n",
        "    # try numeric conversion where possible\n",
        "    for c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
        "    return df\n",
        "\n",
        "# Robust parser for a single file (Petrel-like)\n",
        "def parse_petrel_file(path):\n",
        "    with open(path, 'r', errors='ignore') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Find first non-empty, non-comment line and any 'END HEADER'\n",
        "    first_non_comment = None\n",
        "    header_line_index = None\n",
        "    data_start_index = None\n",
        "    for i, line in enumerate(lines):\n",
        "        s = line.strip()\n",
        "        if s == \"\":\n",
        "            continue\n",
        "        if first_non_comment is None:\n",
        "            first_non_comment = i\n",
        "        if re.search(r'END\\s+HEADER', line, re.IGNORECASE):\n",
        "            data_start_index = i + 1\n",
        "            break\n",
        "\n",
        "    if data_start_index is None:\n",
        "        if first_non_comment is None:\n",
        "            raise ValueError(\"File appears empty (no data lines).\")\n",
        "        sample_line = lines[first_non_comment].strip()\n",
        "        if re.search(r'[A-Za-z]', sample_line):\n",
        "            header_line_index = first_non_comment\n",
        "            data_start_index = first_non_comment + 1\n",
        "        else:\n",
        "            header_line_index = None\n",
        "            data_start_index = first_non_comment\n",
        "\n",
        "    inspect_index = header_line_index if header_line_index is not None else data_start_index\n",
        "    if inspect_index is None or inspect_index >= len(lines):\n",
        "        raise ValueError(\"Could not determine where data starts in file.\")\n",
        "\n",
        "    inspect_line = lines[inspect_index].strip()\n",
        "\n",
        "    # Detect delimiter\n",
        "    if ',' in inspect_line:\n",
        "        sep = ','\n",
        "    elif '\\t' in inspect_line:\n",
        "        sep = '\\t'\n",
        "    else:\n",
        "        # prefer regex whitespace if there are runs of multiple spaces\n",
        "        if re.search(r'\\s{2,}', inspect_line):\n",
        "            sep = r'\\s+'\n",
        "        else:\n",
        "            sep = r'\\s+'\n",
        "\n",
        "    # Build text chunk for pandas\n",
        "    if header_line_index is not None:\n",
        "        text_chunk = ''.join(lines[header_line_index:])  # include header line\n",
        "    else:\n",
        "        text_chunk = ''.join(lines[data_start_index:])  # no header\n",
        "\n",
        "    # Try reading with pandas\n",
        "    try:\n",
        "        if sep in (',', '\\t'):\n",
        "            if header_line_index is not None:\n",
        "                df = pd.read_csv(StringIO(text_chunk), sep=sep, engine='python')\n",
        "            else:\n",
        "                df = pd.read_csv(StringIO(text_chunk), sep=sep, engine='python', header=None)\n",
        "        else:\n",
        "            if header_line_index is not None:\n",
        "                df = pd.read_csv(StringIO(text_chunk), sep=sep, engine='python')\n",
        "            else:\n",
        "                df = pd.read_csv(StringIO(text_chunk), sep=sep, engine='python', header=None)\n",
        "    except Exception as e:\n",
        "        # Fallback: manual whitespace/token split per line\n",
        "        rows = []\n",
        "        for ln in text_chunk.splitlines():\n",
        "            if not ln.strip():\n",
        "                continue\n",
        "            # try to protect commas inside quotes\n",
        "            if '\"' in ln or \"'\" in ln:\n",
        "                # replace commas inside quotes with a token\n",
        "                def _replace_inside_quotes(s, char=',', token='<<C>>'):\n",
        "                    out = []\n",
        "                    in_q = False; qchar = None\n",
        "                    for ch in s:\n",
        "                        if ch in ('\"', \"'\"):\n",
        "                            if not in_q:\n",
        "                                in_q = True; qchar = ch\n",
        "                            elif ch == qchar:\n",
        "                                in_q = False; qchar = None\n",
        "                            out.append(ch)\n",
        "                        elif in_q and ch == char:\n",
        "                            out.append(token)\n",
        "                        else:\n",
        "                            out.append(ch)\n",
        "                    return ''.join(out)\n",
        "                ln2 = _replace_inside_quotes(ln)\n",
        "                parts = re.split(r'\\s+', ln2.strip())\n",
        "                parts = [p.replace('<<C>>', ',') for p in parts]\n",
        "            else:\n",
        "                parts = re.split(r'\\s+', ln.strip())\n",
        "            rows.append(parts)\n",
        "        if not rows:\n",
        "            raise ValueError(\"Fallback split produced no rows.\")\n",
        "        maxc = max(len(r) for r in rows)\n",
        "        norm = [r + ['']*(maxc-len(r)) for r in rows]\n",
        "        # if header_line_index was present, treat first row as header\n",
        "        if header_line_index is not None:\n",
        "            header = [h.strip() if h.strip() else f\"col_{i+1}\" for i,h in enumerate(norm[0])]\n",
        "            data_rows = norm[1:]\n",
        "        else:\n",
        "            header = [f\"col_{i+1}\" for i in range(maxc)]\n",
        "            data_rows = norm\n",
        "        df = pd.DataFrame(data_rows, columns=header)\n",
        "\n",
        "    # Strip surrounding quotes from string columns\n",
        "    for col in df.select_dtypes(include='object').columns:\n",
        "        df[col] = df[col].astype(str).str.strip().str.strip('\"').str.strip(\"'\")\n",
        "\n",
        "    return df, sep, header_line_index is not None\n",
        "\n",
        "# Common fallback sentinels if none are detected in header\n",
        "COMMON_SENTINELS = [-999.25, -999.250000, -999.0, -999, -9999]\n",
        "\n",
        "# Process multiple uploaded files\n",
        "out_csv_paths = []\n",
        "for fname in uploaded.keys():\n",
        "    print(\"Processing:\", fname)\n",
        "    try:\n",
        "        # Try to detect sentinel values from first ~40 lines\n",
        "        try:\n",
        "            with open(fname, 'r', errors='ignore') as fh:\n",
        "                head_text = ''.join([next(fh) for _ in range(40)])\n",
        "        except Exception:\n",
        "            head_text = \"\"\n",
        "        detected_sent = detect_sentinels(head_text)\n",
        "        sentinels = detected_sent if detected_sent else COMMON_SENTINELS\n",
        "\n",
        "        df, used_sep, had_header = parse_petrel_file(fname)\n",
        "        df = replace_sentinels_in_df(df, sentinels)\n",
        "\n",
        "        out_name = os.path.splitext(fname)[0] + \"_converted.csv\"\n",
        "        df.to_csv(out_name, index=False)\n",
        "        out_csv_paths.append(out_name)\n",
        "        print(f\" -> saved: {out_name}  (rows={len(df):,}, cols={df.shape[1]})\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR parsing {fname}: {e}\")\n",
        "\n",
        "if not out_csv_paths:\n",
        "    raise SystemExit(\"No CSVs were generated.\")\n",
        "\n",
        "# Prepare ZIP of all CSVs for easy download\n",
        "zipname = \"all_converted_csvs.zip\"\n",
        "with zipfile.ZipFile(zipname, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    for p in out_csv_paths:\n",
        "        zf.write(p, arcname=os.path.basename(p))\n",
        "\n",
        "print(\"\\nCreated ZIP:\", zipname)\n",
        "files.download(zipname)\n",
        "\n",
        "# OPTIONAL: also provide individual CSV downloads (uncomment if you want)\n",
        "# for p in out_csv_paths:\n",
        "#     files.download(p)\n",
        "\n",
        "print(\"\\nDone. Converted files:\")\n",
        "for p in out_csv_paths:\n",
        "    print(\"  -\", p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "0zZrI3dLJOlG",
        "outputId": "3d061f33-d04c-4ec1-97d6-9e775eb9fe5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select one or more Petrel ASCII / text files to upload (Ctrl/Cmd+click to multi-select)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b5a5bea-e2de-4753-8e3b-521c3060e21f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b5a5bea-e2de-4753-8e3b-521c3060e21f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Etive to Etive\n",
            "Saving Ness to Ness\n",
            "Saving Tarbert to Tarbert\n",
            "Processing: Etive\n",
            " -> saved: Etive_converted.csv  (rows=104, cols=4)\n",
            "Processing: Ness\n",
            " -> saved: Ness_converted.csv  (rows=92, cols=4)\n",
            "Processing: Tarbert\n",
            " -> saved: Tarbert_converted.csv  (rows=121, cols=4)\n",
            "\n",
            "Created ZIP: all_converted_csvs.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n",
            "/tmp/ipython-input-548963754.py:37: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c].astype(str).str.replace(',', ''), errors='ignore')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_319d5d5b-5600-42e8-b00b-3b5ea05bd489\", \"all_converted_csvs.zip\", 4562)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done. Converted files:\n",
            "  - Etive_converted.csv\n",
            "  - Ness_converted.csv\n",
            "  - Tarbert_converted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tu3V0aQF_kLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Seismic interpretation time txt files to csv format**"
      ],
      "metadata": {
        "id": "IunqaV3HAzBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab multi-file converter  TXT to Csv\n",
        "!pip install -q pandas\n",
        "from google.colab import files\n",
        "import pandas as pd, re, zipfile, os\n",
        "from io import StringIO\n",
        "\n",
        "print(\"Select one or more TXT files to upload (Ctrl/Cmd+click)...\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise SystemExit(\"No files uploaded.\")\n",
        "\n",
        "def simple_detect_sep(text):\n",
        "    if '\\t' in text: return '\\t'\n",
        "    if ',' in text and text.count(',') >= text.count(' '): return ','\n",
        "    return r'\\s+'\n",
        "\n",
        "def convert_bytes_to_df(b, fname):\n",
        "    txt = b.decode('utf-8', errors='ignore')\n",
        "    # drop initial comments\n",
        "    lines = [ln for ln in txt.splitlines() if ln.strip() and not ln.strip().startswith(('#','//','~','%'))]\n",
        "    if not lines:\n",
        "        return pd.DataFrame()\n",
        "    # header detection\n",
        "    first = lines[0].strip()\n",
        "    alpha = sum(bool(re.search('[A-Za-z]', tok)) for tok in re.split(r'\\s+', first))\n",
        "    nums  = sum(1 for tok in re.split(r'\\s+', first) if re.match(r'^-?\\d+(\\.\\d+)?$', tok))\n",
        "    has_header = alpha > nums and alpha>0\n",
        "\n",
        "    sample = '\\n'.join(lines[:30])\n",
        "    sep = simple_detect_sep(sample)\n",
        "\n",
        "    if sep in (',','\\t'):\n",
        "        if has_header:\n",
        "            df = pd.read_csv(StringIO('\\n'.join(lines)), sep=sep, engine='python')\n",
        "        else:\n",
        "            df = pd.read_csv(StringIO('\\n'.join(lines)), sep=sep, engine='python', header=None)\n",
        "    else:\n",
        "        # fallback to robust splitting line-by-line\n",
        "        rows=[]\n",
        "        for ln in lines:\n",
        "            parts = re.split(r'\\s+', ln.strip())\n",
        "            rows.append(parts)\n",
        "        maxc = max(len(r) for r in rows)\n",
        "        rows = [r + ['']*(maxc-len(r)) for r in rows]\n",
        "        if has_header:\n",
        "            header = rows[0]\n",
        "            data = rows[1:]\n",
        "            df = pd.DataFrame(data, columns=header)\n",
        "        else:\n",
        "            df = pd.DataFrame(rows)\n",
        "    df = df.replace([-999.25, -999.250000, -999, -999.0], pd.NA)\n",
        "    return df\n",
        "\n",
        "out_csvs = []\n",
        "for fname, b in uploaded.items():\n",
        "    print(\"Converting:\", fname)\n",
        "    df = convert_bytes_to_df(b, fname)\n",
        "    outname = fname.rsplit('.',1)[0] + '_converted.csv'\n",
        "    df.to_csv(outname, index=False)\n",
        "    out_csvs.append(outname)\n",
        "    print(\" -> saved:\", outname)\n",
        "\n",
        "# zip them\n",
        "zipname = \"all_converted_csvs.zip\"\n",
        "with zipfile.ZipFile(zipname, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for p in out_csvs:\n",
        "        zf.write(p)\n",
        "print(\"Created:\", zipname)\n",
        "files.download(zipname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "j99lUbCO5dCp",
        "outputId": "8ae7c67f-14f2-4bb6-df97-4ae5ba280f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select one or more TXT files to upload (Ctrl/Cmd+click)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-150b905a-7eb6-46d0-a969-e77408a7ae09\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-150b905a-7eb6-46d0-a969-e77408a7ae09\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Base Cretaceous.txt to Base Cretaceous.txt\n",
            "Saving Top Etive.txt to Top Etive.txt\n",
            "Saving Top Ness.txt to Top Ness.txt\n",
            "Saving Top Tarbert.txt to Top Tarbert.txt\n",
            "Converting: Base Cretaceous.txt\n",
            " -> saved: Base Cretaceous_converted.csv\n",
            "Converting: Top Etive.txt\n",
            " -> saved: Top Etive_converted.csv\n",
            "Converting: Top Ness.txt\n",
            " -> saved: Top Ness_converted.csv\n",
            "Converting: Top Tarbert.txt\n",
            " -> saved: Top Tarbert_converted.csv\n",
            "Created: all_converted_csvs.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0886528a-4441-48c2-a86c-b6be156307ff\", \"all_converted_csvs.zip\", 1612418)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}